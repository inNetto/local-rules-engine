# Local Rules Engine

A Node.js system that uses Ollama local AI to apply business rules to text using natural language processing and intelligent analysis.

## ğŸš€ Setup

### Prerequisites
- Node.js 16+
- Ollama installed and running locally
- llama3 model downloaded in Ollama

### Installation

```bash
# Install dependencies
npm install

# Verify Ollama is running
curl http://localhost:11434/api/tags
```

### Configure Ollama
```bash
# Download llama3 model
ollama pull llama3

# Check available models
ollama list
```

## ğŸ“ Usage

### Quick Start (All Services)
```bash
# Install all dependencies
npm run setup-frontend

# Start both backend and frontend
npm run start-all
```
This will start both the backend (port 3001) and frontend (port 5173).

### Option 1: Web Interface (Recommended)
```bash
# Start backend server
PORT=3001 npm run server

# In another terminal, start frontend
cd frontend
npm run dev
```
Then open http://localhost:5173 in your browser for a beautiful web interface.

### Option 2: CLI Mode
```bash
npm start
```

### Option 3: REST API Only
```bash
# Development
PORT=3001 npm run dev

# Production
PORT=3001 npm run server
```

## ğŸ–¥ï¸ Frontend Interface

The project includes a beautiful Vue 3 + Tailwind CSS frontend located in the `frontend/` directory.

### Features:
- ğŸ¨ Modern, responsive design with Tailwind CSS v3
- âš¡ Real-time text analysis
- ğŸ“Š Server status monitoring
- ğŸ”„ Clear error handling and loading states
- ğŸ“‹ Display of active business rules
- ğŸŒ CORS-enabled communication with backend

### Frontend Setup:
```bash
cd frontend
npm install
npm run dev
```

The frontend will be available at http://localhost:5173

## ğŸŒ API Endpoints

### POST /evaluate
Evaluates input using defined rules.

**Request:**
```json
{
  "input": "Text to analyze"
}
```

**Response:**
```json
{
  "success": true,
  "input": "Text to analyze",
  "result": "Analysis result from AI",
  "timestamp": "2025-08-25T15:17:31.598Z"
}
```

### GET /health
Server health check.

### GET /
API documentation and information.

**Request:**
```json
{
  "input": "John Silva has email john@test.com"
}
```

**Response:**
```json
{
  "success": true,
  "input": "John Silva has email john@test.com",
  "result": "Status: APPROVED\nObservations: Valid email...",
  "timestamp": "2025-08-25T10:00:00.000Z"
}
```

### GET /health
Service health check.

### GET /
API documentation.

## ğŸ“‹ Configured Rules

The rules are defined in `rules.txt` and include:
- Email validation
- Numeric limit verification
- Date validation
- Code detection
- Format analysis

## ğŸ”§ Customization

To modify rules, edit the `rules.txt` file and restart the service.

## ğŸ“¦ Project Structure

```
local-rules-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js                 # Main RulesEngine class
â”‚   â”œâ”€â”€ server.js               # Express REST server
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ ollamaService.js    # Ollama communication service
â”œâ”€â”€ rules.txt                  # Business rules in natural language
â”œâ”€â”€ package.json                # Project configuration
â””â”€â”€ README.md                   # This file
```

## ğŸ›  Development

```bash
# Install dependencies
npm install

# Run in development mode
npm run dev

# Run CLI version
npm start

# Run server
npm run server
```

## ğŸ“– How it Works

1. **Load Rules**: The system reads business rules from `rules.txt`
2. **Process Input**: User input is combined with rules to form a prompt
3. **AI Analysis**: The prompt is sent to Ollama's llama3 model
4. **Return Results**: The AI's analysis is returned to the user

## ğŸ” Example Rules

The system can analyze:
- Email format validation
- Numeric ranges (0-1000)
- Date formats (DD/MM/YYYY)
- Text formatting issues
- Code language detection
- Business logic compliance

## ğŸš¨ Requirements

- Ollama must be running on `localhost:11434`
- llama3 model must be available
- Node.js ES modules support (type: "module" in package.json)

## ğŸ“„ License

MIT
